<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/images/pages/icon.ico"><link rel="icon" href="/images/pages/icon.ico"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="syntomic"><meta name="keywords" content="Pure mathematics to everything"><meta name="description" content="随着数据处理的逻辑变得越来越复杂，编写的SQL也会变得越加复杂，有时甚至会感觉SQL力不从心。这个时候就需要扩展SQL的表达能力，而UDF(用户自定义函数)就是这样一种扩张开发的机制，拓展系统的内置函数，实现自定义逻辑。本编文章我们就从具体场景出发，使用各种Flink UDF去优化或解决相关问题。"><meta property="og:type" content="article"><meta property="og:title" content="SQL Is All Your Need: Flink SQL UDF"><meta property="og:url" content="https://syntomic.cn/2023/05/11/SQL-Is-All-Your-Need-Flink-SQL-UDF/index.html"><meta property="og:site_name" content="syntomic"><meta property="og:description" content="随着数据处理的逻辑变得越来越复杂，编写的SQL也会变得越加复杂，有时甚至会感觉SQL力不从心。这个时候就需要扩展SQL的表达能力，而UDF(用户自定义函数)就是这样一种扩张开发的机制，拓展系统的内置函数，实现自定义逻辑。本编文章我们就从具体场景出发，使用各种Flink UDF去优化或解决相关问题。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://image-host.obs.cn-east-2.myhuaweicloud.com/articles/cumulative.png"><meta property="og:image" content="https://nightlies.apache.org/flink/flink-docs-master/fig/pyflink_process_execution_mode.png#id=RQ3s2&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title="><meta property="og:image" content="https://nightlies.apache.org/flink/flink-docs-release-1.17/fig/pyflink_embedded_execution_mode.png#id=KRU4p&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title="><meta property="article:published_time" content="2023-05-11T09:48:46.000Z"><meta property="article:modified_time" content="2024-01-07T12:54:06.293Z"><meta property="article:author" content="syntomic"><meta property="article:tag" content="Flink SQL"><meta property="article:tag" content="Paimon"><meta property="article:tag" content="教程"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://image-host.obs.cn-east-2.myhuaweicloud.com/articles/cumulative.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>SQL Is All Your Need: Flink SQL UDF - syntomic</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"syntomic.cn",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:"52ffd2958d1ad7b0a200567bc76df02a",google:{measurement_id:null},tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"tyYLzPKD7m92XfM9u67vOMWo-MdYXbMMI",app_key:"uMqs8pWO2jeOMY1JCH4ocYv2",server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>if(!Fluid.ctx.dnt){var _hmt=_hmt||[];!function(){var t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?52ffd2958d1ad7b0a200567bc76df02a";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()}</script><script async>Fluid.ctx.dnt||Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=",(function(){function a(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],a("js",new Date),a("config","")}))</script><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>syntomic</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="SQL Is All Your Need: Flink SQL UDF"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-05-11 17:48" pubdate>2023年5月11日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 17 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">SQL Is All Your Need: Flink SQL UDF</h1><p id="updated-time" class="note note-info">本文最后更新于 2024年1月7日 晚上</p><div class="markdown-body"><p>随着数据处理的逻辑变得越来越复杂，编写的SQL也会变得越加复杂，有时甚至会感觉SQL力不从心。这个时候就需要扩展SQL的表达能力，而UDF(用户自定义函数)就是这样一种扩张开发的机制，拓展系统的内置函数，实现自定义逻辑。本编文章我们就从具体场景出发，使用各种Flink UDF去优化或解决相关问题。</p><span id="more"></span><h1>事前准备</h1><ul><li>UDF大致有以下几种<ul><li>数值函数(UDF): 将标量值转换成一个新标量值，如：<code>DATE_FORMAT</code></li><li>表值函数(UDTF): 将标量值转换成新的行数据, 如：<code>EXPLODE</code></li><li>聚合函数(UDAF)：将多行数据里的标量值转换为成一个新标量值, 如：<code>SUM</code></li></ul></li><li>不同计算引擎有相应的实现方法，本编文章我们只考虑<a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/functions/udfs/">Flink自定义UDF</a><ul><li>继承相应类：<strong>注意输出输入类型推导</strong></li><li>实现相应方法</li><li>注册使用</li></ul></li></ul><blockquote><p>注：文中不会给出详细代码，只会对一些重要的地方给予说明，详细实现可到<a target="_blank" rel="noopener" href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-udf/src/main/java/cn/syntomic/qflink/sql/udf">代码库</a>中查看。</p></blockquote><h1>ETL</h1><p>文章<a target="_blank" rel="noopener" href="https://syntomic.github.io/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/#ETL">SQL Is All Your Need: Flink SQL</a>中我们提出了一个问题，如何简化ETL中重复的SQL代码，现在我们就用UDTF来实现这一目的。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> `dwd_log`<br><span class="hljs-keyword">SELECT</span><br>    REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">1</span>) <span class="hljs-keyword">AS</span> `<span class="hljs-type">time</span>`,<br>    REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">AS</span> `key_word`,<br><br>    <span class="hljs-built_in">JSON_VALUE</span>(REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">3</span>), <span class="hljs-string">&#x27;$.key1&#x27;</span> RETURNING <span class="hljs-type">INT</span>) <span class="hljs-keyword">AS</span> `key1`,<br>    <span class="hljs-built_in">JSON_VALUE</span>(REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">3</span>), <span class="hljs-string">&#x27;$.key2&#x27;</span>) <span class="hljs-keyword">AS</span> `key2`<br><span class="hljs-keyword">FROM</span><br>    `ods_log`<br></code></pre></td></tr></table></figure><ul><li>原因：上述SQL看起来冗长最重要的原因是需要先将每个字段用正则提取，然后再对字段进行相同JSON解析操作，导致了很多重复代码。</li><li>解决：可以在Flink SQL中编写UDTF，与常规的标量函数只能返回一个值不同，它可以返回任意多行，且每一行可以包含多列。通过LATERAL算子将外表(算子左侧)的每一行跟表值函数返回的所有行(算子右侧)进行笛卡尔积，这样就一次性提取多个字段，那我们的代码就能简化很多：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> q_regex_extract <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;cn.syntomic.qflink.sql.udf.table.QRegexExtract&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> JAVA;<br><br><span class="hljs-keyword">SELECT</span><br>    `<span class="hljs-type">time</span>`,<br>    `key_word`,<br>    `json`<br><span class="hljs-keyword">FROM</span><br>    `ods_log`, <span class="hljs-keyword">LATERAL</span> <span class="hljs-keyword">TABLE</span>(q_regex_extract(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;key_word&#x27;</span>, <span class="hljs-string">&#x27;json&#x27;</span>))<br></code></pre></td></tr></table></figure><ul><li>同样地，我们利用hive module使用hive函数一次性进行JSON解析</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql">LOAD <span class="hljs-keyword">MODULE</span> hive <span class="hljs-keyword">WITH</span> (<span class="hljs-string">&#x27;hive-version&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;3.1.3&#x27;</span>);<br><br><span class="hljs-keyword">SELECT</span><br>    `<span class="hljs-type">time</span>`,<br>    `key_word`,<br>    <span class="hljs-comment">-- json_tuple return string type</span><br>    <span class="hljs-built_in">CAST</span>(`key1` <span class="hljs-keyword">AS</span> <span class="hljs-type">INT</span>) <span class="hljs-keyword">AS</span> `key1`,<br>    `key2`<br><span class="hljs-keyword">FROM</span><br>    (<br>        <span class="hljs-comment">-- above sql</span><br>        ...<br>    ) a, <span class="hljs-keyword">LATERAL</span> <span class="hljs-keyword">TABLE</span>(json_tuple(`json`, <span class="hljs-string">&#x27;key1&#x27;</span>, <span class="hljs-string">&#x27;key2&#x27;</span>)) <span class="hljs-keyword">AS</span> b(`key1`, `key2`);<br></code></pre></td></tr></table></figure><ul><li>这样我们就利用UDTF，减少了SQL中重复代码，形成统一的清洗逻辑，同时避免<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/FLINK-21573">Flink重复计算的问题</a>，对比之前的实现就看起来逻辑更加清晰，也更加简洁~</li></ul><blockquote><p>注: 我们再自定义函数中<code>q_regex_extract</code>没有别名就可以直接相应字段, 这是因为我们自定义了类型推导, 而在函数<code>json_tuple</code>中就必须显示别名相应字段：</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> TypeInference <span class="hljs-title function_">getTypeInference</span><span class="hljs-params">(DataTypeFactory typeFactory)</span> &#123;<br>    <span class="hljs-keyword">return</span> TypeInference.newBuilder()<br>                .outputTypeStrategy(<br>                        callContext -&gt; &#123;<br>                            List&lt;Field&gt; fields = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;(argsLen - <span class="hljs-number">2</span>);<br><br>                            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">2</span>; i &lt; argsLen; i++) &#123;<br>                                <span class="hljs-comment">// use literal parameter as field name</span><br>                                <span class="hljs-type">String</span> <span class="hljs-variable">fieldName</span> <span class="hljs-operator">=</span><br>                                        callContext<br>                                                .getArgumentValue(i, String.class)<br>                                                .orElse(<span class="hljs-string">&quot;f&quot;</span> + (i - <span class="hljs-number">2</span>));<br>                                fields.add(i - <span class="hljs-number">2</span>, DataTypes.FIELD(fieldName, DataTypes.STRING()));<br>                            &#125;<br><br>                            <span class="hljs-keyword">return</span> Optional.of(DataTypes.ROW(fields.toArray(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Field</span>[<span class="hljs-number">0</span>])));<br>                        &#125;)<br>                .build();<br>&#125;<br></code></pre></td></tr></table></figure><h1>Analysis</h1><p>文章<a target="_blank" rel="noopener" href="https://syntomic.github.io/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/#Analysis">SQL Is All Your Need: Flink SQL</a>中我们计算了每分钟滑动窗口的UV。现在我们把问题变复杂一点：每分钟计算一次当天截至到目前的累积UV<br><img src="https://image-host.obs.cn-east-2.myhuaweicloud.com/articles/cumulative.png" srcset="/img/loading.gif" lazyload alt=""></p><ul><li>Flink SQL在1.13之后提供了累积窗口的计算方式：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    DATE_FORMAT(`window_start`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    DATE_FORMAT(`window_end`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>) <span class="hljs-keyword">AS</span> `window_end`,<br>    `key_word` <span class="hljs-keyword">AS</span> `dim`,<br>    <span class="hljs-built_in">COUNT</span>(<span class="hljs-keyword">DISTINCT</span> `key2`) <span class="hljs-keyword">AS</span> `metric`<br><span class="hljs-keyword">FROM</span><br>    <span class="hljs-keyword">TABLE</span>(CUMULATE(<span class="hljs-keyword">TABLE</span> `dwd_log`, DESCRIPTOR(`rowtime`), <span class="hljs-type">INTERVAL</span> <span class="hljs-string">&#x27;1&#x27;</span> MINUTES, <span class="hljs-type">INTERVAL</span> <span class="hljs-string">&#x27;1&#x27;</span> DAYS))<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> `key_word`, `window_start`, `window_end`;<br></code></pre></td></tr></table></figure><ul><li>但如果需要我们自己实现的时候，似乎比较难以实现？我们这里只考虑离线的情况，因为Flink(1.15)离线计算时暂不支持累计窗口去重计算。</li><li>一种比较直接的想法是首先计算每天所有的时间窗口，然后与小于当前结束窗口的数据JOIN, 计算出相应时间窗口的基数。但这样计算会导致数据膨胀严重，当数据量大时会导致数据倾斜等问题。可以采取下列方法进行优化：<ul><li>累积窗口计算只需要当天分组下最早时间的记录，这样可以大大减少数据量。</li><li>调整相应资源以及参数实现自适应执行。</li></ul></li><li>其实大数据场景中有很多基数估算的方法，这里我们可以引入HLL(HyperLogLog) —— 基数统计的概率算法，用另外一种方法实现<ul><li>对HLL感兴趣的同学可以参考文章<a target="_blank" rel="noopener" href="https://www.cnblogs.com/wmyskxz/p/12396393.html">神奇的HyperLogLog</a>，以及<a target="_blank" rel="noopener" href="http://content.research.neustar.biz/blog/hll.html">线上演示Demo</a>。</li><li>HLL可以在1.2kb内存下估算高达1亿个元素，而只有2%的误差！</li><li>我们可以使用HLL数据结构这样去计算当天每分钟的累积人数：</li></ul></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> hll_agg <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;cn.syntomic.qflink.sql.udf.aggregate.HLLAggregate&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> JAVA;<br><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> hll_cardinality <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;cn.syntomic.qflink.sql.udf.scalar.HLLCardinality&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> JAVA;<br><br><span class="hljs-keyword">SELECT</span><br>    DATE_FORMAT(`min_time`, <span class="hljs-string">&#x27;yyyy-MM-dd 00:00:00&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    FROM_UNIXTIME(UNIX_TIMESTAMP(`min_time`) <span class="hljs-operator">+</span> <span class="hljs-number">60</span>) <span class="hljs-keyword">AS</span> `window_end`,<br>    `key_word` <span class="hljs-keyword">AS</span> `dim`,<br>    <span class="hljs-comment">-- 按照每分钟时间排序，合并第一行到当前行每分钟的HLL结构，并估算其基数</span><br>    hll_cardinality(hll_agg(min_hll) <span class="hljs-keyword">OVER</span> (<span class="hljs-keyword">PARTITION</span> <span class="hljs-keyword">BY</span> `key_word` <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> `min_time`)) <span class="hljs-keyword">AS</span> `metric`<br><span class="hljs-keyword">FROM</span><br>    (<br>        <span class="hljs-comment">-- 聚合每分钟数据形成HLL数据结构</span><br>        <span class="hljs-keyword">SELECT</span><br>            DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:00&#x27;</span>) <span class="hljs-keyword">AS</span> `min_time`,<br>            `key_word`,<br>            hll_agg(`key2`) <span class="hljs-keyword">AS</span> min_hll<br>        <span class="hljs-keyword">FROM</span><br>            `dwd_log`<br>        <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>            DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:00&#x27;</span>),<br>            `key_word`<br>    ) a;<br></code></pre></td></tr></table></figure><ul><li>在Flink中HLL不是预定义的数据结构, 所以累加器中需要将其视为<code>RAW</code>数据格式，利用<code>KYRO</code>序列化</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HLLBuffer</span> &#123;<br><br>    <span class="hljs-meta">@DataTypeHint(allowRawGlobally = HintFlag.TRUE)</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">HLL</span> <span class="hljs-variable">hll</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">HLL</span>(<span class="hljs-number">11</span>, <span class="hljs-number">5</span>);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>这样我们就利用udf引入新的数据结构，扩展了SQL的表达能力~</li></ul><h1>Python UDF</h1><p>有时我们需要结合Python生态去实现动态执行、模型预测等功能，这个时候就可以引入Python UDF解决。这里我们以经典的鸢尾花机器学习分类为例。</p><ul><li>原理<ul><li>进程模式：Python函数和Java算子之间采用Grpc服务通信 <img src="https://nightlies.apache.org/flink/flink-docs-master/fig/pyflink_process_execution_mode.png#id=RQ3s2&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=" srcset="/img/loading.gif" lazyload alt=""></li><li>线程模式：Python函数和Java算子运行在同一个进程，利用<a target="_blank" rel="noopener" href="https://syntomic.github.io/2023/02/25/Java%E8%B0%83%E7%94%A8Python/">FFI通信</a><br><img src="https://nightlies.apache.org/flink/flink-docs-release-1.17/fig/pyflink_embedded_execution_mode.png#id=KRU4p&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=" srcset="/img/loading.gif" lazyload alt=""><ul><li>这样可以减少进程间序列化的开销，提升性能</li></ul></li></ul></li><li>实现：<ul><li>实现相应Python类，导入模型进行预测</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DemoUDF</span>(<span class="hljs-title class_ inherited__">ScalarFunction</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">open</span>(<span class="hljs-params">self, function_context: FunctionContext</span>):<br>        self.model = joblib.load(path)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eval</span>(<span class="hljs-params">self, value</span>):<br>        <span class="hljs-keyword">return</span> self.model.predict(np.array(value).reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)).tolist()[<span class="hljs-number">0</span>]<br><br><br>demo_udf = udf(DemoUDF(), result_type=DataTypes.INT())<br></code></pre></td></tr></table></figure><ul><li>注册Python UDF</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;python.files&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;./qflink-python/src/main/python/q-pyflink/udf&#x27;</span>;<br><span class="hljs-comment">-- 保证python算子获得足够资源</span><br><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;pipeline.operator-chaining&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;false&#x27;</span>;<br><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;python.execution-mode&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;thread&#x27;</span>;<br><br><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> demo_udf <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;scalar.demo_udf.demo_udf&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> PYTHON;<br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> `source` (<br>    `sepal_length` <span class="hljs-type">FLOAT</span>,<br>    `sepal_width` <span class="hljs-type">FLOAT</span>,<br>    `petal_length` <span class="hljs-type">FLOAT</span>,<br>    `petal_width` <span class="hljs-type">FLOAT</span><br>) <span class="hljs-keyword">WITH</span> (<br>    <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;datagen&#x27;</span>,<br>    <span class="hljs-string">&#x27;rows-per-second&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;1&#x27;</span><br>);<br><br><span class="hljs-keyword">SELECT</span><br>    demo_udf(<span class="hljs-keyword">ARRAY</span>[`sepal_length`, `sepal_width`, `petal_length`, `petal_width`]) <span class="hljs-keyword">AS</span> `<span class="hljs-keyword">classifier</span>`<br><span class="hljs-keyword">FROM</span><br>    `source`;<br></code></pre></td></tr></table></figure><blockquote><p>注: 需提前创建Python虚拟环境，安装pyflink依赖且激活；若Python算子是CPU密集型任务，则需调整TM CPU个数</p></blockquote><h1>Summary</h1><p>大数据技术发展日新月异，但_SQL NEVER DIE_ ！本文讨论了如何利用UDF来来提升SQL的表达能力，希望可以提升你对<code>SQL Is ALL Your Need</code>的信心。但技术没有银弹，SQL不可能解决所有的问题。不管是SQL还是底层API，其实都是解决问题的方式，需要根据具体问题采用合适的工具，甚至可以<a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/data_stream_api/">结合SQL的通用性以及底层API的灵活性</a>来优雅地解决问题~</p><blockquote><p>本文所有SQL代码可参考：<a target="_blank" rel="noopener" href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-sdk/src/test/resources/sqls/sql_is_all_your_need/flink_sql_udf">SQL IS ALL Your Need: Flink SQL UDF</a></p></blockquote></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%95%B0%E6%8D%AE/" class="category-chain-item">数据</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/Flink-SQL/" class="print-no-link">#Flink SQL</a> <a href="/tags/Paimon/" class="print-no-link">#Paimon</a> <a href="/tags/%E6%95%99%E7%A8%8B/" class="print-no-link">#教程</a></div></div><div class="license-box my-3"><div class="license-title"><div>SQL Is All Your Need: Flink SQL UDF</div><div>https://syntomic.cn/2023/05/11/SQL-Is-All-Your-Need-Flink-SQL-UDF/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>syntomic</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年5月11日</div></div><div class="license-meta-item license-meta-date"><div>更新于</div><div>2024年1月7日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/06/15/SQL-Is-All-Your-Need-Flink-Dynamic-SQL/" title="SQL Is All Your Need: Flink Dynamic SQL"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">SQL Is All Your Need: Flink Dynamic SQL</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/" title="SQL Is All Your Need: Flink SQL"><span class="hidden-mobile">SQL Is All Your Need: Flink SQL</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="waline"></div><script type="text/javascript">Fluid.utils.loadComments("#waline",(function(){Fluid.utils.createCssLink("https://cdn.staticfile.org/waline/2.15.5/waline.min.css"),Fluid.utils.createScript("https://cdn.staticfile.org/waline/2.15.5/waline.min.js",(function(){var i=Object.assign({serverURL:"http://1.94.30.163:8360/",path:"window.location.pathname",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],dark:'html[data-user-color-scheme="dark"]',wordLimit:0,pageSize:10},{el:"#waline",path:window.location.pathname});Waline.init(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{var i="#waline .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>