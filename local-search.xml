<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Flink规则引擎</title>
    <link href="/2023/07/15/Flink%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/"/>
    <url>/2023/07/15/Flink%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/</url>
    
    <content type="html"><![CDATA[<p>随着业务发展, 对风控能力的要求会越来越高，比如丰富的事件类型处理、不同的统计方式计算、动态的规则配置支持等。本篇文章我们就来讨论如何利用Flink构建一个规则引擎，去解决这些问题，来支持风控平台的建设。</p><span id="more"></span><h1 id="风控业务"><a href="#风控业务" class="headerlink" title="风控业务"></a>风控业务</h1><ul><li><p>类型</p><ul><li>事先风控：提前辨识异常，避免风险事件的发生。</li><li>事中风控：实时识别异常，减少风险事件的影响。</li><li>事后风控：总结分析异常，防止类似事件再次产生。</li></ul></li><li><p>方法</p><ul><li>基于规则<ul><li>统计规则：例如5分钟以内访问次数大于100次</li><li>序列规则：例如用户点击、加入购物车、删除事件序列</li></ul></li><li>基于算法</li></ul></li><li><p>本篇文章只考虑利用统计规则做事中的风控: 根据规则将实时数据源中异常事件筛选出来</p></li></ul><h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><ul><li>利用<a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/broadcast_state/">广播流</a>广播规则到各个算子上，然后数据遍历相应规则进行处理输出。原始思路可见<a href="https://flink.apache.org/2020/01/15/advanced-flink-application-patterns-vol.1-case-study-of-a-fraud-detection-system/">Flink官方博客</a></li></ul><p><img src="https://flink.apache.org/img/blog/2019-11-19-demo-fraud-detection/end-to-end.png" alt="整体流程"></p><h2 id="Flink作业"><a href="#Flink作业" class="headerlink" title="Flink作业"></a>Flink作业</h2><ul><li><p>利用参数<code>job.id</code>划分作业处理规则的范围，一个作业只处理相同<code>job_id</code>的规则。</p></li><li><p>由于<a href="https://flink.apache.org/2020/04/15/flink-serialization-tuning-vol.-1-choosing-your-serializer-if-you-can/">Flink序列化效率的差别</a>, 所以一个作业只处理相同Schema的数据，这样的就能统一采用<code>Row</code>数据类型进行高效序列化。<br>  <img src="https://flink.apache.org/img/blog/2020-04-15-flink-serialization-performance-results.svg" alt="序列化效率"></p><ul><li>这里我们引入<a href="https://docs.oracle.com/cd/E26161_02/html/GettingStartedGuide/avroschemas.html">Avro Schema</a>定义字段类型：  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;record&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;default&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;rule_id&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;int&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li></ul></li><li><p>同时如果原始数据源量级比较大，我们可以先统一合并读取拆分出关心的数据，减少公共层压力, 所以这里也顺便提供了纯ETL的功能，通过作业参数<code>agg.enable = false</code>设置。</p></li></ul><h2 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h2><ul><li><p>我们提供下列配置项</p><ul><li><p>过滤条件: 根据计算表达式过滤满足条件的数据</p></li><li><p>清洗条件</p><ul><li>正则解析</li><li>JSONPath解析</li><li>字段表达式</li></ul></li><li><p>分组条件：根据关注对象进行分组计算</p></li><li><p>窗口条件</p><ul><li>窗口类型：滚动&#x2F;滑动&#x2F;累积</li><li>窗口触发：单次&#x2F;批次</li><li>窗口大小及偏移</li></ul></li><li><p>聚合条件</p><ul><li>聚合过滤：计算表达式</li><li>聚合方法：SUM&#x2F;COUNT&#x2F;COUNT DISTINCT等</li></ul></li><li><p>阈值条件：利用聚合指标的计算表达式判断</p></li><li><p>以及规则元数据</p><ul><li>规则ID：主键</li><li>规则状态：控制规则生效状态</li><li>作业ID: 匹配相应Flink作业</li></ul></li></ul></li><li><p>例子：将数据进行过滤、解析、字段映射、窗口聚合计算、阈值判断的整体流程</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;rule_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rule_state&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ACTIVE&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;job_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;test&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;filter&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;expr&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;string.contains(raw, &#x27;stdout&#x27;)&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;params&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-string">&quot;raw&quot;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;flat_map&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;pattern&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125; \\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;) (.*?) (.*)&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;normal_fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;time&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;STRING&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key_word&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;STRING&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;JSON&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;json_paths&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-punctuation">&#123;</span><br>                        <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key1&quot;</span><span class="hljs-punctuation">,</span><br>                        <span class="hljs-attr">&quot;expr&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$.key1&quot;</span><span class="hljs-punctuation">,</span><br>                        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;INT&quot;</span><span class="hljs-punctuation">,</span><br>                        <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>                    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>                    <span class="hljs-punctuation">&#123;</span><br>                        <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key2&quot;</span><span class="hljs-punctuation">,</span><br>                        <span class="hljs-attr">&quot;expr&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$.key2&quot;</span><span class="hljs-punctuation">,</span><br>                        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;STRING&quot;</span><span class="hljs-punctuation">,</span><br>                        <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>                    <span class="hljs-punctuation">&#125;</span><br>                <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;mapping_fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;is_odd&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;BOOLEAN&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;expr&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key1 % 2 == 1&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;default&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;keys&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-string">&quot;is_odd&quot;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;window&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TUMBLE&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;trigger&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SINGLE&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;offset&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;size&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">86400000</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;step&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;aggregates&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;val_cnt&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-string">&quot;key2&quot;</span><br>            <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;method&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;COUNT_DISTINCT&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;threshold&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;expr&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;val_cnt &gt; 1&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;params&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-string">&quot;val_cnt&quot;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li></ul><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="Connector"><a href="#Connector" class="headerlink" title="Connector"></a>Connector</h2><ul><li><p>Source：通过自定义<code>RowDeserializationSchema</code>根据传入的Avro Schema进行数据规范化</p></li><li><p>Sink：根据<code>TopicSelector</code>(Kafka)根据关键字拆分到不同Topic</p></li></ul><h2 id="ETL算子"><a href="#ETL算子" class="headerlink" title="ETL算子"></a>ETL算子</h2><ul><li><p>规则流：根据规则状态更新广播状态</p></li><li><p>数据流：遍历所有广播状态中规则进行处理</p><ul><li>引入高性能、轻量级<a href="https://github.com/killme2008/aviatorscript/tree/master">Aviator</a>表达式引擎提升表达能力</li><li>如果下游需要聚合，根据<code>rule_id</code> + 按照<code>keys</code>字段取值进行分组。这样下游就相当于固定逻辑处理，减少代码复杂度。</li></ul></li></ul><blockquote><p>注1：因为我们这里可以得到规则相应的聚合条件，所以可以在ETL算子中做预聚合减少下游数据量，提升吞吐量。</p></blockquote><blockquote><p>注2: 遍历规则会导致数据重复, 当规则过多时可能会产生性能问题。这里可以先合并相同过滤+窗口+聚合条件的规则, 减少处理压力。</p></blockquote><h2 id="AGG算子"><a href="#AGG算子" class="headerlink" title="AGG算子"></a>AGG算子</h2><ul><li><p>Flink原生窗口算子不支持动态变更，所以我们需要设计重新窗口算子。</p></li><li><p>通过阅读<a href="https://blog.jrwang.me/2019/flink-source-code-time-and-window/">Flink源码</a>可知窗口实现过程：</p><ul><li>通过<code>WindowAssigner</code>确定消息所在的窗口（可能属于多个窗口）</li><li>将数据根据<code>AggregateFunction</code>聚合到对应窗口的状态中</li><li>根据<code>Trigger</code>确定是否应该触发窗口结果的计算，如果使用 InternalWindowFunction 对窗口进行处理</li><li>注册<code>EventTimeTimer</code>定时器，进行窗口触发计算及结束时清理窗口状态</li><li>如果数据延迟到达，提交到<code>SideOutput</code>中</li></ul></li><li><p>所以只要我们先从广播状态中根据当前分组拿到相应规则，就可以模拟窗口算子的逻辑，实现窗口的动态配置~</p></li><li><p>这里需要注意一些问题：</p><ol><li>窗口触发：因为需要处理数据和规则的双流输入，而Flink的Watermark是取得双流中最小的Watermark，所以这里我们需要定义规则流的Watermark为周期性触发的<code>Long.MAX_VALUE</code>，这样才不会影响数据流正常窗口触发计算。</li><li>状态清理：但规则移除后，肯定希望清理相应规则下的所有累积状态，要不然之后肯定会OOM。这里我们在移除广播流规则时，可以根据规则ID拿到规则相关的所有聚合状态进行删除。删除时也要注意并发问题，可以采用先复制相应键进行避免。</li><li>聚合计算：因为DataStream API中窗口是利用数据复制实现的，长时间周期，短步长的窗口类型会导致严重的性能问题。这里可以借鉴SQL API中<a href="https://www.jianshu.com/p/a990e113b042">Window slice</a>实现。</li></ol></li></ul><blockquote><p>注: 这里采用<code>AbstractStreamOperator</code>实现而不是标准的<code>KeyedBroadcastProcessFunction</code>实现是因为需要得到窗口触发时对应的窗口对象，需要利用底层状态的<code>Namespace</code>进行判断。</p></blockquote><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><ul><li>作为一个通用型的平台作业，所有需要编写相应的单元测试、算子测试、作业测试保证代码质量，具体操作可见<a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/datastream/testing/">Flink测试</a>。<ul><li>这里我们将source 和 sink 设置成可插拔的，可以在不改动代码的条件下实现作业测试。</li></ul></li></ul><h1 id="业界实现"><a href="#业界实现" class="headerlink" title="业界实现"></a>业界实现</h1><ul><li><p>社区提出<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=195730308">动态CEP的提案</a>, 希望提供动态CEP规则的支持，但暂时还没实现。</p></li><li><p>不过业界有对应实现：</p><ul><li><a href="https://developer.aliyun.com/article/994446">阿里</a>：<a href="https://help.aliyun.com/zh/flink/developer-reference/definitions-of-rules-in-the-json-format-in-dynamic-flink-cep?spm=a2c4g.11186623.0.0.559f3086jvWbnz#concept-2258817">商业版本</a></li><li><a href="https://mp.weixin.qq.com/s/PT8ImeOOheXR295gQRsN8w">字节</a></li></ul></li><li><p>我们提供的方法也可以支持相应CEP配置，不过感觉CEP的配置过于复杂，需要更好地设计前端平台，降低使用门槛。</p></li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇文章我们详细讨论了如何利用Flink构建规则引擎支持风控平台的建设，得到了一些构建复杂数据处理应用的经验，也更加深入理解了Flink处理数据的原理，向知其所以然迈向了坚实的一步~</p>]]></content>
    
    
    <categories>
      
      <category>教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
      <tag>风控</tag>
      
      <tag>架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SQL Is All Your Need: Flink Dynamic SQL</title>
    <link href="/2023/06/15/SQL-Is-All-Your-Need-Flink-Dynamic-SQL/"/>
    <url>/2023/06/15/SQL-Is-All-Your-Need-Flink-Dynamic-SQL/</url>
    
    <content type="html"><![CDATA[<p>实时监控是Flink一个重要且复杂的应用场景，所以一般不会只采用SQL去实现。但本篇文章我们将从一个简单的问题出发，挑战只使用SQL满足逐渐复杂的需求，希望最终可以明确SQL的使用边界。</p><span id="more"></span><h1 id="事先准备"><a href="#事先准备" class="headerlink" title="事先准备"></a>事先准备</h1><ul><li><p>我们有日志流如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> `dwd_log` (<br>    `<span class="hljs-type">time</span>` STRING COMMENT <span class="hljs-string">&#x27;事件时间&#x27;</span>,<br>    `key_word` STRING COMMENT <span class="hljs-string">&#x27;日志标识&#x27;</span>,<br>    `key1` <span class="hljs-type">INT</span> COMMENT <span class="hljs-string">&#x27;指标&#x27;</span>,<br>    `key2` STRING COMMENT <span class="hljs-string">&#x27;维度&#x27;</span><br>) <span class="hljs-keyword">WITH</span> (<br>    ...<br>);<br></code></pre></td></tr></table></figure></li><li><p>数据示例如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">&#123;&quot;time&quot;:&quot;2023-04-09 15:40:05&quot;,&quot;key_word&quot;:&quot;stdout&quot;,&quot;key1&quot;:5,&quot;key2&quot;:&quot;val1&quot;&#125;<br></code></pre></td></tr></table></figure></li><li><p>我们将根据一些规则从这个日志流中筛选出关注的事件。</p></li></ul><h1 id="阶段一：需求的开始"><a href="#阶段一：需求的开始" class="headerlink" title="阶段一：需求的开始"></a>阶段一：需求的开始</h1><blockquote><p>规则1：每天日志关键字为<code>stdout</code>每个维度<code>key2</code>获得指标<code>key1</code>次数大于1的事件</p></blockquote><ul><li><p>这个规则可以用简单的SQL实现如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    <span class="hljs-number">1</span> <span class="hljs-keyword">AS</span> `rule_id`,<br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd 00:00:00&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    `key2` <span class="hljs-keyword">AS</span> `key`,<br>    <span class="hljs-built_in">MAX</span>(`<span class="hljs-type">time</span>`) <span class="hljs-keyword">AS</span> `alert_time`,<br>    MAP[<span class="hljs-string">&#x27;key1&#x27;</span>, <span class="hljs-built_in">CAST</span>(<span class="hljs-built_in">COUNT</span>(`key1`) <span class="hljs-keyword">AS</span> <span class="hljs-keyword">DOUBLE</span>)] <span class="hljs-keyword">AS</span> `alert_metrics`<br><span class="hljs-keyword">FROM</span><br>    `dwd_log`<br><span class="hljs-keyword">WHERE</span><br>    `key_word` <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;stdout&#x27;</span><br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>    `key2`,<br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd 00:00:00&#x27;</span>)<br><span class="hljs-keyword">HAVING</span><br>    <span class="hljs-built_in">COUNT</span>(`key1`) <span class="hljs-operator">&gt;</span> <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure></li><li><p>所以对这种单个简单的统计规则，用Flink SQL实现会非常方便，但当规则越来越多时呢？</p></li></ul><h1 id="阶段二：需求的增长"><a href="#阶段二：需求的增长" class="headerlink" title="阶段二：需求的增长"></a>阶段二：需求的增长</h1><blockquote><p>规则2：每小时日志中不同维度<code>key2</code>数量大于2的事件</p></blockquote><ul><li><p>当多个类似的需求出现时，直截了当的做法就是将不同规则<code>UNION</code>起来：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    <span class="hljs-number">1</span> <span class="hljs-keyword">AS</span> `rule_id`,<br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd 00:00:00&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    `key2` <span class="hljs-keyword">AS</span> `key`,<br>    <span class="hljs-built_in">MAX</span>(`<span class="hljs-type">time</span>`) <span class="hljs-keyword">AS</span> `alert_time`,<br>    MAP[<span class="hljs-string">&#x27;key1_cnt&#x27;</span>, <span class="hljs-built_in">CAST</span>(<span class="hljs-built_in">COUNT</span>(`key1`) <span class="hljs-keyword">AS</span> <span class="hljs-keyword">DOUBLE</span>)] <span class="hljs-keyword">AS</span> `alert_metrics`<br><span class="hljs-keyword">FROM</span><br>    `dwd_log`<br><span class="hljs-keyword">WHERE</span><br>    `key_word` <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;stdout&#x27;</span><br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>    `key2`,<br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd 00:00:00&#x27;</span>)<br><span class="hljs-keyword">HAVING</span><br>    <span class="hljs-built_in">COUNT</span>(`key1`) <span class="hljs-operator">&gt;</span> <span class="hljs-number">1</span><br><span class="hljs-keyword">UNION</span> <span class="hljs-keyword">ALL</span><br><span class="hljs-keyword">SELECT</span><br>    <span class="hljs-number">2</span> <span class="hljs-keyword">AS</span> `rule_id`,<br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:00:00&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    `key_word` <span class="hljs-keyword">AS</span> `key`,<br>    <span class="hljs-built_in">MAX</span>(`<span class="hljs-type">time</span>`) <span class="hljs-keyword">AS</span> `alert_time`,<br>    MAP[<span class="hljs-string">&#x27;key2_cnt&#x27;</span>, <span class="hljs-built_in">CAST</span>(<span class="hljs-built_in">COUNT</span>(<span class="hljs-keyword">DISTINCT</span> `key2`) <span class="hljs-keyword">AS</span> <span class="hljs-keyword">DOUBLE</span>)] <span class="hljs-keyword">AS</span> `alert_metrics`<br><span class="hljs-keyword">FROM</span><br>    `dwd_log`<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>    `key_word`,<br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:00:00&#x27;</span>)<br><span class="hljs-keyword">HAVING</span><br>    <span class="hljs-built_in">COUNT</span>(<span class="hljs-keyword">DISTINCT</span> `key2`) <span class="hljs-operator">&gt;</span> <span class="hljs-number">2</span>;<br></code></pre></td></tr></table></figure></li><li><p>虽然这样实现逻辑简单，但涉及重复消费，计算消耗大，且将规则硬编码在代码中，不够灵活。我们需要在达到临界点时之前找到更好的解决方法。</p></li></ul><h1 id="阶段三：需求的爆发"><a href="#阶段三：需求的爆发" class="headerlink" title="阶段三：需求的爆发"></a>阶段三：需求的爆发</h1><ul><li><p>我们看到当需求增长后，将面临以下问题：</p><ul><li>重复消费导致的计算资源浪费</li><li>合并后代码过长导致无法维护</li><li>硬编码导致规则没有灵活调整等</li></ul></li><li><p>所以这时需要重构SQL代码，找到一种不用改变SQL又能支持规则CRUD的方法</p><ul><li>仔细思考一下现有的规则1和规则2，发现它们都是由相同的部分组成<ul><li>过滤规则：对应<code>WHERE</code>条件</li><li>分组规则：对应监控对象, 规则1中的<code>key2</code>字段以及规则2中的<code>key_word</code>字段</li><li>窗口规则：对应监控周期，规则1中的<code>天</code>以及规则2的<code>小时</code></li><li>聚合规则：对应聚合计算，规则1中的<code>COUNT</code>方法以及规则2中的<code>COUNT DISTINCT</code>方法</li><li>阈值规则：对应<code>HAVING</code>条件</li></ul></li></ul></li><li><p>这时我们可以抽象出一个规则模型，将规则放入另外一张(Paimon)表中维护</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> `dim_rule` (<br>    `rule_id` <span class="hljs-type">INT</span> COMMENT <span class="hljs-string">&#x27;规则id&#x27;</span>,<br>    `job_id` STRING COMMENT <span class="hljs-string">&#x27;处理规则作业id&#x27;</span>,<br>    `<span class="hljs-keyword">filter</span>` STRING COMMENT <span class="hljs-string">&#x27;过滤规则&#x27;</span>,<br>    `key` STRING COMMENT <span class="hljs-string">&#x27;分组规则&#x27;</span>,<br>    `<span class="hljs-keyword">window</span>` STRING COMMENT <span class="hljs-string">&#x27;窗口规则&#x27;</span>,<br>    `aggregate` <span class="hljs-type">ROW</span><span class="hljs-operator">&lt;</span>`name` STRING, `input` STRING, `<span class="hljs-keyword">method</span>` STRING<span class="hljs-operator">&gt;</span> COMMENT <span class="hljs-string">&#x27;聚合规则&#x27;</span>,<br>    `threshold` STRING COMMENT <span class="hljs-string">&#x27;阈值规则&#x27;</span>,<br>    <span class="hljs-keyword">PRIMARY</span> KEY(`rule_id`) <span class="hljs-keyword">NOT</span> ENFORCED<br>);<br></code></pre></td></tr></table></figure></li><li><p>规则示例为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;rule_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;job_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;test&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;filter&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key_word==&#x27;stdout&#x27;&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;key&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key2&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;window&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;DAY&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;aggregate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key1_cnt&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key1&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;method&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;COUNT&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;threshold_rule&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;key1_cnt&gt;1&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li><li><p>有了规则的抽象之后，我们就可以拿日志数据去关联规则，然后根据规则去做具体的处理，当然这里就需要引入几个UDF来增强SQL的表达能力(这里我们不去讨论UDF<a href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-udf/src/main/java/cn/syntomic/qflink/sql/udf">具体实现</a>)</p><ul><li><code>dynamic_key</code>(UDF): 根据分组规则取日志中的相应值</li><li><code>dynamic_window</code>(UDF)：根据窗口规则划分日志到相应窗口，类似之前的<code>DATE_FORMAT</code>函数</li><li><code>dynamic_filter</code>(UDF)：根据过滤规则或阈值规则的表达式，判断表达式是否满足条件</li><li><code>dynamic_agg</code>(UDAF)：根据聚合规则中计算聚合值，最终输出<code>指标名：值</code>的映射</li></ul></li><li><p>重构后的代码如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    `rule_id`,<br>    `window_start`,<br>    `key`,<br>    <span class="hljs-built_in">MAX</span>(`<span class="hljs-type">time</span>`) <span class="hljs-keyword">AS</span> `alert_time`,<br>    <span class="hljs-comment">-- 根据聚合规则进行计算</span><br>    dynamic_agg(`data`, `aggregate`) <span class="hljs-keyword">AS</span> `alert_metrics`<br><span class="hljs-keyword">FROM</span><br>    (<br>        <span class="hljs-keyword">SELECT</span><br>            `rule_id`,<br>            dynamic_window(`<span class="hljs-type">time</span>`, `<span class="hljs-keyword">window</span>`) <span class="hljs-keyword">AS</span> `window_start`,<br>            dynamic_key(`data`, `key`) <span class="hljs-keyword">AS</span> `key`,<br>            `aggregate`,<br>            `threshold`,<br>            `<span class="hljs-type">time</span>`,<br>            <span class="hljs-comment">-- 其中`data`为ROW(`key_word`, `key1`, `key2`)，由于规则中是不确定的，需要可以访问到日志中每一个字段</span><br>            `data`<br>        <span class="hljs-keyword">FROM</span><br>            `dwd_log` <span class="hljs-keyword">AS</span> `log`<br>        <span class="hljs-keyword">LEFT</span> <span class="hljs-keyword">JOIN</span><br>            <span class="hljs-comment">-- Paimon规则维表查询</span><br>            `dim_rule` <span class="hljs-keyword">FOR</span> <span class="hljs-built_in">SYSTEM_TIME</span> <span class="hljs-keyword">AS</span> <span class="hljs-keyword">OF</span> `log`.`proc_time` <span class="hljs-keyword">AS</span> `rule`<br>        <span class="hljs-comment">-- 只关联作业相关规则</span><br>        <span class="hljs-keyword">ON</span> `rule`.`job_id` <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test&#x27;</span><br>        <span class="hljs-keyword">WHERE</span><br>            <span class="hljs-comment">-- 根据规则过滤日志</span><br>            dynamic_filter(`data`, `<span class="hljs-keyword">filter</span>`) <span class="hljs-keyword">AND</span> `rule_id` <span class="hljs-keyword">IS</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span><br>    ) `log_with_rule`<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>    <span class="hljs-comment">-- 根据规则分组</span><br>    `key`, `rule_id`, `window_start`, `threshold`, `aggregate`<br><span class="hljs-keyword">HAVING</span><br>    <span class="hljs-comment">-- 根据阈值规则判断聚合结果是否超过阈值</span><br>    dynamic_filter(dynamic_agg(`data`, `aggregate`), `threshold`);<br></code></pre></td></tr></table></figure></li></ul><blockquote><p>注：在实现过程中发现无法重命名<code>ROW</code>类型中字段，所以在上述规则示例中实际需要指定默认名，即<code>EXPR$0, EXPR$1, EXPR$2</code>。大家也可以思考一下为什么不用<code>MAP</code>类型?</p></blockquote><ul><li>经过这样的重构之后，SQL代码就固定了，所有操作只是针对规则的CRUD。但还会有什么其他问题吗？</li></ul><h1 id="阶段四：需求的挑战"><a href="#阶段四：需求的挑战" class="headerlink" title="阶段四：需求的挑战"></a>阶段四：需求的挑战</h1><ul><li><p>上述方法采用维表关联，每来一条数据都需要对维表进行全表扫描，当日志和规则量级增加后，会带来相应的性能问题。虽然可以采用异步、缓存等<a href="https://paimon.apache.org/docs/master/how-to/lookup-joins/">SQL HINTS</a>缓解，但其实不是根本的解决方案。</p></li><li><p>幸好Paimon提供了增量读的功能，我们可以将规则表全部读取到Flink中，并可以捕获规则表中的数据变更，这样就和数据源解耦了，不会带来额外的性能压力。这只需改变一行代码就可以实现:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    ...<br><span class="hljs-keyword">FROM</span><br>    (<br>        <span class="hljs-keyword">SELECT</span><br>            ...<br>        <span class="hljs-keyword">FROM</span><br>            `dwd_log` <span class="hljs-keyword">AS</span> `log`<br>        <span class="hljs-keyword">LEFT</span> <span class="hljs-keyword">JOIN</span><br>            <span class="hljs-comment">-- 修改为常规的左连接</span><br>            `dim_rule` <span class="hljs-keyword">AS</span> `rule`<br>        <span class="hljs-keyword">ON</span> `rule`.`job_id` <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test&#x27;</span><br>        ...<br>    ) `log_with_rule`<br>...<br></code></pre></td></tr></table></figure></li><li><p>看起来去利用SQL进行复杂监控的目标达到了，但事实真的是这样吗？</p></li></ul><h1 id="真相"><a href="#真相" class="headerlink" title="真相"></a>真相</h1><ul><li><p>其实我们还会碰见一系列棘手的问题：</p><ul><li>报警控制：SQL的实现周期内报警会反复触发报警，如需控制报警次数，只能下游再进行处理</li><li>窗口类型：SQL的实现只能在指定周期内实时累积，不能定时轮询(比如每天触发一次)</li><li>状态控制：SQL的实现当规则修改时没法细粒度地控制之前累积状态，作业在长期运行后会不堪重负等</li></ul></li><li><p>但实际工作中，我们大部分碰到的问题其实就是类似阶段一那样确定的规则，都可以利用SQL方便地进行解决。而从长远来看，上层的数据应用会变得更加简单，对于最终用户，所有的数据都可以使用SQL方式进行分析，这就是我理解的<code>SQL Is All Your Need</code>愿景。</p></li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul><li>在本篇文章中看到了SQL解决复杂问题潜力，但也明白SQL解决问题的局限性，但这并不影响我们的愿景, 而且在随着AI的发展，可以憧憬仅用自然语言处理数据的时代。<em><strong>Keep up with the times</strong></em> ~</li></ul><blockquote><p>本文所有SQL代码可参考：<a href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-sdk/src/test/resources/sqls/sql_is_all_your_need/flink_dynamic_sql">SQL IS ALL Your Need: Flink Dynamic SQL</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink SQL</tag>
      
      <tag>Flink</tag>
      
      <tag>Paimon</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SQL Is All Your Need: Flink SQL UDF</title>
    <link href="/2023/05/11/SQL-Is-All-Your-Need-Flink-SQL-UDF/"/>
    <url>/2023/05/11/SQL-Is-All-Your-Need-Flink-SQL-UDF/</url>
    
    <content type="html"><![CDATA[<p>随着数据处理的逻辑变得越来越复杂，编写的SQL也会变得越加复杂，有时甚至会感觉SQL力不从心。这个时候就需要扩展SQL的表达能力，而UDF(用户自定义函数)就是这样一种扩张开发的机制，拓展系统的内置函数，实现自定义逻辑。本编文章我们就从具体场景出发，使用各种Flink UDF去优化或解决相关问题。</p><span id="more"></span><h1 id="事前准备"><a href="#事前准备" class="headerlink" title="事前准备"></a>事前准备</h1><ul><li><p>UDF大致有以下几种</p><ul><li>数值函数(UDF): 将标量值转换成一个新标量值，如：<code>DATE_FORMAT</code></li><li>表值函数(UDTF): 将标量值转换成新的行数据, 如：<code>EXPLODE</code></li><li>聚合函数(UDAF)：将多行数据里的标量值转换为成一个新标量值, 如：<code>SUM</code></li></ul></li><li><p>不同计算引擎有相应的实现方法，本编文章我们只考虑<a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/functions/udfs/">Flink自定义UDF</a></p><ul><li>继承相应类：<strong>注意输出输入类型推导</strong></li><li>实现相应方法</li><li>注册使用</li></ul></li></ul><blockquote><p>注：文中不会给出详细代码，只会对一些重要的地方给予说明，详细实现可到<a href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-udf/src/main/java/cn/syntomic/qflink/sql/udf">代码库</a>中查看。</p></blockquote><h1 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h1><p>文章<a href="https://syntomic.github.io/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/">SQL Is All Your Need: Flink SQL</a>中我们提出了一个问题，如何简化ETL中重复的SQL代码，现在我们就用UDTF来实现这一目的。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> `dwd_log`<br><span class="hljs-keyword">SELECT</span><br>    REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">1</span>) <span class="hljs-keyword">AS</span> `<span class="hljs-type">time</span>`,<br>    REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">AS</span> `key_word`,<br><br>    <span class="hljs-built_in">JSON_VALUE</span>(REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">3</span>), <span class="hljs-string">&#x27;$.key1&#x27;</span> RETURNING <span class="hljs-type">INT</span>) <span class="hljs-keyword">AS</span> `key1`,<br>    <span class="hljs-built_in">JSON_VALUE</span>(REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">3</span>), <span class="hljs-string">&#x27;$.key2&#x27;</span>) <span class="hljs-keyword">AS</span> `key2`<br><span class="hljs-keyword">FROM</span><br>    `ods_log`<br></code></pre></td></tr></table></figure><ul><li><p>原因：上述SQL看起来冗长最重要的原因是需要先将每个字段用正则提取，然后再对字段进行相同JSON解析操作，导致了很多重复代码。</p></li><li><p>解决：可以在Flink SQL中编写UDTF，与常规的标量函数只能返回一个值不同，它可以返回任意多行，且每一行可以包含多列。通过LATERAL算子将外表(算子左侧)的每一行跟表值函数返回的所有行(算子右侧)进行笛卡尔积，这样就一次性提取多个字段，那我们的代码就能简化很多：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> q_regex_extract <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;cn.syntomic.qflink.sql.udf.table.QRegexExtract&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> JAVA;<br><br><span class="hljs-keyword">SELECT</span><br>    `<span class="hljs-type">time</span>`,<br>    `key_word`,<br>    `json`<br><span class="hljs-keyword">FROM</span><br>    `ods_log`, <span class="hljs-keyword">LATERAL</span> <span class="hljs-keyword">TABLE</span>(q_regex_extract(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-string">&#x27;time&#x27;</span>, <span class="hljs-string">&#x27;key_word&#x27;</span>, <span class="hljs-string">&#x27;json&#x27;</span>))<br></code></pre></td></tr></table></figure></li><li><p>同样地，我们利用hive module使用hive函数一次性进行JSON解析</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql">LOAD <span class="hljs-keyword">MODULE</span> hive <span class="hljs-keyword">WITH</span> (<span class="hljs-string">&#x27;hive-version&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;3.1.3&#x27;</span>);<br><br><span class="hljs-keyword">SELECT</span><br>    `<span class="hljs-type">time</span>`,<br>    `key_word`,<br>    <span class="hljs-comment">-- json_tuple return string type</span><br>    <span class="hljs-built_in">CAST</span>(`key1` <span class="hljs-keyword">AS</span> <span class="hljs-type">INT</span>) <span class="hljs-keyword">AS</span> `key1`,<br>    `key2`<br><span class="hljs-keyword">FROM</span><br>    (<br>        <span class="hljs-comment">-- above sql</span><br>        ...<br>    ) a, <span class="hljs-keyword">LATERAL</span> <span class="hljs-keyword">TABLE</span>(json_tuple(`json`, <span class="hljs-string">&#x27;key1&#x27;</span>, <span class="hljs-string">&#x27;key2&#x27;</span>)) <span class="hljs-keyword">AS</span> b(`key1`, `key2`);<br></code></pre></td></tr></table></figure></li><li><p>这样我们就利用UDTF，减少了SQL中重复代码，形成统一的清洗逻辑，同时避免<a href="https://issues.apache.org/jira/browse/FLINK-21573">Flink重复计算的问题</a>，对比之前的实现就看起来逻辑更加清晰，也更加简洁~</p></li></ul><blockquote><p>注: 我们再自定义函数中<code>q_regex_extract</code>没有别名就可以直接相应字段, 这是因为我们自定义了类型推导, 而在函数<code>json_tuple</code>中就必须显示别名相应字段：</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> TypeInference <span class="hljs-title function_">getTypeInference</span><span class="hljs-params">(DataTypeFactory typeFactory)</span> &#123;<br>    <span class="hljs-keyword">return</span> TypeInference.newBuilder()<br>                .outputTypeStrategy(<br>                        callContext -&gt; &#123;<br>                            List&lt;Field&gt; fields = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;(argsLen - <span class="hljs-number">2</span>);<br><br>                            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">2</span>; i &lt; argsLen; i++) &#123;<br>                                <span class="hljs-comment">// use literal parameter as field name</span><br>                                <span class="hljs-type">String</span> <span class="hljs-variable">fieldName</span> <span class="hljs-operator">=</span><br>                                        callContext<br>                                                .getArgumentValue(i, String.class)<br>                                                .orElse(<span class="hljs-string">&quot;f&quot;</span> + (i - <span class="hljs-number">2</span>));<br>                                fields.add(i - <span class="hljs-number">2</span>, DataTypes.FIELD(fieldName, DataTypes.STRING()));<br>                            &#125;<br><br>                            <span class="hljs-keyword">return</span> Optional.of(DataTypes.ROW(fields.toArray(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Field</span>[<span class="hljs-number">0</span>])));<br>                        &#125;)<br>                .build();<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h1><p>文章<a href="https://syntomic.github.io/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/">SQL Is All Your Need: Flink SQL</a>中我们计算了每分钟滑动窗口的UV。现在我们把问题变复杂一点：每分钟计算一次当天截至到目前的累积UV <img src="https://nightlies.apache.org/flink/flink-docs-master/fig/cumulating-windows.png" alt="累积窗口"></p><ul><li><p>当然，在Flink SQL提供了相应的累积窗口计算：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    DATE_FORMAT(`window_start`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    DATE_FORMAT(`window_end`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>) <span class="hljs-keyword">AS</span> `window_end`,<br>    `key_word` <span class="hljs-keyword">AS</span> `dim`,<br>    <span class="hljs-built_in">COUNT</span>(<span class="hljs-keyword">DISTINCT</span> `key2`) <span class="hljs-keyword">AS</span> `metric`<br><span class="hljs-keyword">FROM</span><br>    <span class="hljs-keyword">TABLE</span>(CUMULATE(<span class="hljs-keyword">TABLE</span> `dwd_log`, DESCRIPTOR(`rowtime`), <span class="hljs-type">INTERVAL</span> <span class="hljs-string">&#x27;1&#x27;</span> MINUTES, <span class="hljs-type">INTERVAL</span> <span class="hljs-string">&#x27;1&#x27;</span> DAYS))<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> `key_word`, `window_start`, `window_end`;<br></code></pre></td></tr></table></figure></li><li><p>但如果需要我们自己实现的时候，似乎比较难以实现？</p></li><li><p>一种比较直接的想法是首先计算每天所有的时间窗口，然后与小于当前结束窗口的数据JOIN, 计算出相应时间窗口的基数。但这样计算会导致数据膨胀严重，当数据量大时会导致数据倾斜等问题。可以采取下列方法进行优化：</p><ul><li><p>累积窗口计算只需要当天分组下最早时间的记录，这样可以大大减少数据量</p></li><li><p>调整相应资源以及参数实现自适应执行</p></li></ul></li><li><p>大数据场景中有很多基数估算的方法，这里我们引入HLL(HyperLogLog) —— 基数统计的概率算法，用另外一种方法实现</p><ul><li>考虑一个抛硬币的游戏：连续掷n次硬币，然后说出连续掷为正面的最大次数maxbit，猜测一共抛了多少次?</li></ul>  <img src="/2023/05/11/SQL-Is-All-Your-Need-Flink-SQL-UDF/HLL.png" class="" title="HyperLogLog"><ul><li><p>利用概率知识可知n大概为2^maxbit。进一步地利用分桶平均等手段减少方差，HLL可以在1.2kb内存下估算高达2^27的元素个数,只有2%的误差！</p></li><li><p>这样我们就可以使用HLL就可以很容易地去计算当天每分钟的累积人数</p>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> hll_agg <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;cn.syntomic.qflink.sql.udf.aggregate.HLLAggregate&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> JAVA;<br><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> hll_cardinality <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;cn.syntomic.qflink.sql.udf.scalar.HLLCardinality&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> JAVA;<br><br><span class="hljs-keyword">SELECT</span><br>    DATE_FORMAT(`min_time`, <span class="hljs-string">&#x27;yyyy-MM-dd 00:00:00&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    FROM_UNIXTIME(UNIX_TIMESTAMP(`min_time`) <span class="hljs-operator">+</span> <span class="hljs-number">60</span>) <span class="hljs-keyword">AS</span> `window_end`,<br>    `key_word` <span class="hljs-keyword">AS</span> `dim`,<br>    <span class="hljs-comment">-- 按照每分钟时间排序，合并第一行到当前行每分钟的HLL结构，并估算其基数</span><br>    hll_cardinality(hll_agg(min_hll) <span class="hljs-keyword">OVER</span> (<span class="hljs-keyword">PARTITION</span> <span class="hljs-keyword">BY</span> `key_word` <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> `min_time`)) <span class="hljs-keyword">AS</span> `metric`<br><span class="hljs-keyword">FROM</span><br>    (<br>        <span class="hljs-comment">-- 聚合每分钟数据形成HLL数据结构</span><br>        <span class="hljs-keyword">SELECT</span><br>            DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:00&#x27;</span>) <span class="hljs-keyword">AS</span> `min_time`,<br>            `key_word`,<br>            hll_agg(`key2`) <span class="hljs-keyword">AS</span> min_hll<br>        <span class="hljs-keyword">FROM</span><br>            `dwd_log`<br>        <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>            DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:00&#x27;</span>),<br>            `key_word`<br>    ) a;<br></code></pre></td></tr></table></figure></li><li><p>在Flink中HLL不是预定义的数据结构, 所以累加器中需要将其视为<code>RAW</code>数据格式，利用<code>KYRO</code>序列化</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HLLBuffer</span> &#123;<br><br>    <span class="hljs-meta">@DataTypeHint(allowRawGlobally = HintFlag.TRUE)</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">HLL</span> <span class="hljs-variable">hll</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">HLL</span>(<span class="hljs-number">11</span>, <span class="hljs-number">5</span>);<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>对HLL感兴趣的同学可以参考<a href="https://www.cnblogs.com/wmyskxz/p/12396393.html">神奇的HyperLogLog</a></p></li></ul></li><li><p>这样我们就利用udf引入新的数据结构，扩展了SQL的表达能力~</p></li></ul><h1 id="Python-UDF"><a href="#Python-UDF" class="headerlink" title="Python UDF"></a>Python UDF</h1><p>有时我们需要结合Python生态去实现动态执行、模型预测等功能，这个时候就可以引入Python UDF解决。这里我们以经典的鸢尾花机器学习分类为例。</p><ul><li><p>原理</p><ul><li>进程模式：Python函数和Java算子之间采用Grpc服务通信 <img src="https://nightlies.apache.org/flink/flink-docs-master/fig/pyflink_process_execution_mode.png" alt="进程模式"></li><li>线程模式：Python函数和Java算子运行在同一个进程，利用<a href="https://syntomic.github.io/2023/02/25/Java%E8%B0%83%E7%94%A8Python/">FFI通信</a> <img src="https://nightlies.apache.org/flink/flink-docs-release-1.17/fig/pyflink_embedded_execution_mode.png" alt="线程模式"><ul><li>这样可以减少进程间序列化的开销，提升性能</li></ul></li></ul></li><li><p>实现：</p><ul><li><p>实现相应Python类，导入模型进行预测</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DemoUDF</span>(<span class="hljs-title class_ inherited__">ScalarFunction</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">open</span>(<span class="hljs-params">self, function_context: FunctionContext</span>):<br>        self.model = joblib.load(path)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eval</span>(<span class="hljs-params">self, value</span>):<br>        <span class="hljs-keyword">return</span> self.model.predict(np.array(value).reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)).tolist()[<span class="hljs-number">0</span>]<br><br><br>demo_udf = udf(DemoUDF(), result_type=DataTypes.INT())<br></code></pre></td></tr></table></figure></li><li><p>注册Python UDF</p>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;python.files&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;./qflink-python/src/main/python/q-pyflink/udf&#x27;</span>;<br><span class="hljs-comment">-- 保证python算子获得足够资源</span><br><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;pipeline.operator-chaining&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;false&#x27;</span>;<br><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;python.execution-mode&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;thread&#x27;</span>;<br><br><span class="hljs-keyword">CREATE</span> TEMPORARY <span class="hljs-keyword">FUNCTION</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> demo_udf <span class="hljs-keyword">AS</span> <span class="hljs-string">&#x27;scalar.demo_udf.demo_udf&#x27;</span> <span class="hljs-keyword">LANGUAGE</span> PYTHON;<br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> `source` (<br>    `sepal_length` <span class="hljs-type">FLOAT</span>,<br>    `sepal_width` <span class="hljs-type">FLOAT</span>,<br>    `petal_length` <span class="hljs-type">FLOAT</span>,<br>    `petal_width` <span class="hljs-type">FLOAT</span><br>) <span class="hljs-keyword">WITH</span> (<br>    <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;datagen&#x27;</span>,<br>    <span class="hljs-string">&#x27;rows-per-second&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;1&#x27;</span><br>);<br><br><span class="hljs-keyword">SELECT</span><br>    demo_udf(<span class="hljs-keyword">ARRAY</span>[`sepal_length`, `sepal_width`, `petal_length`, `petal_width`]) <span class="hljs-keyword">AS</span> `<span class="hljs-keyword">classifier</span>`<br><span class="hljs-keyword">FROM</span><br>    `source`;<br></code></pre></td></tr></table></figure></li></ul><blockquote><p>注: 需提前创建Python虚拟环境，安装pyflink依赖且激活；若Python算子是CPU密集型任务，则需调整TM CPU个数</p></blockquote></li><li><p>大数据技术发展日新月异，但<em>SQL NEVER DIE</em> ！</p></li></ul><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>本文中讨论了如何利用UDF来来提升SQL的表达能力，希望可以提升对<code>SQL Is ALL Your Need</code>的信心。但技术没有银弹，SQL不可能解决所有的问题。不管是SQL还是底层API，其实都是解决问题的方式，需要根据具体问题采用合适的工具，甚至可以<a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/data_stream_api/">结合SQL的通用性以及底层API的灵活性</a>来优雅地解决问题~</p><blockquote><p>本文所有SQL代码可参考：<a href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-sdk/src/test/resources/sqls/sql_is_all_your_need/flink_sql_udf">SQL IS ALL Your Need: Flink SQL UDF</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink SQL</tag>
      
      <tag>Flink</tag>
      
      <tag>Paimon</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SQL Is All Your Need: Flink SQL</title>
    <link href="/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/"/>
    <url>/2023/04/28/SQL-Is-All-Your-Need-Flink-SQL/</url>
    
    <content type="html"><![CDATA[<p>大数据开发简单地说就是从一个存储系统经过计算引擎的加工到另外一个存储系统的过程，如果把存储系统抽象为一张表，利用SQL进行处理，那么其实就和传统的数据库查询没有本质的区别。本篇文章利用<a href="https://paimon.apache.org/docs/master/concepts/overview/">Paimon</a>和<a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sql/gettingstarted/">Flink SQL</a>实现数据开发相关示例，迈向SQL Is All Your Need的第一步。</p><span id="more"></span><h1 id="事先准备"><a href="#事先准备" class="headerlink" title="事先准备"></a>事先准备</h1><p>数据收集不在我们这篇文章的讨论范围之内，这里我们假设已经有一张不断插入的包含原始日志数据的paimon表。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 使用paimon catalog记录元数据信息</span><br><span class="hljs-keyword">CREATE</span> CATALOG my_catalog <span class="hljs-keyword">WITH</span> (<br>    <span class="hljs-string">&#x27;type&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;paimon&#x27;</span>,<br>    <span class="hljs-string">&#x27;warehouse&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;file:/tmp/paimon&#x27;</span><br>);<br>USE CATALOG my_catalog;<br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> ods_log (<br>    log STRING<br>) <span class="hljs-keyword">WITH</span> (<br>    <span class="hljs-comment">-- 只考虑INSERT的情况</span><br>    <span class="hljs-string">&#x27;write-mode&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;append-only&#x27;</span><br>);<br></code></pre></td></tr></table></figure><p>其中每条数据形如：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs txt">2023-04-09 15:40:05 stdout &#123;&quot;key1&quot;:5,&quot;key2&quot;:&quot;val1&quot;&#125;<br>2023-04-09 15:41:05 stdout &#123;&quot;key1&quot;:4,&quot;key2&quot;:&quot;val2&quot;&#125;<br>2023-04-09 15:42:05 stdout &#123;&quot;key1&quot;:1,&quot;key2&quot;:&quot;val2&quot;&#125;<br>2023-04-09 15:43:05 stdout &#123;&quot;key1&quot;:5,&quot;key2&quot;:&quot;val3&quot;&#125;<br>2023-04-09 15:44:05 stdout &#123;&quot;key1&quot;:6,&quot;key2&quot;:&quot;val4&quot;&#125;<br></code></pre></td></tr></table></figure><h1 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h1><p>原始日志数据一般不能直接使用，需要先进行结构化清洗，利用Flink实时处理能力，我们可以构造持续的数据管道进行加工:<br><img src="https://nightlies.apache.org/flink/flink-docs-release-1.17/fig/table-streaming/stream-query-stream.png" alt="连续查询"></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> `dwd_log` (<br>    `<span class="hljs-type">time</span>` STRING,<br>    `key_word` STRING,<br>    `key1` <span class="hljs-type">INT</span>,<br>    `key2` STRING,<br>    <span class="hljs-comment">-- 定义事件时间和watermark以缓解数据乱序的对下游计算的影响</span><br>    `rowtime` <span class="hljs-keyword">AS</span> TO_TIMESTAMP_LTZ(UNIX_TIMESTAMP(`<span class="hljs-type">time</span>`), <span class="hljs-number">0</span>),<br>    WATERMARK <span class="hljs-keyword">FOR</span> `rowtime` <span class="hljs-keyword">AS</span> `rowtime` <span class="hljs-operator">-</span> <span class="hljs-type">INTERVAL</span> <span class="hljs-string">&#x27;10&#x27;</span> <span class="hljs-keyword">SECOND</span><br>) <span class="hljs-keyword">WITH</span> (<br>    <span class="hljs-string">&#x27;write-mode&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;append-only&#x27;</span><br>);<br><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> `dwd_log`<br><span class="hljs-keyword">SELECT</span><br>    REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">1</span>) <span class="hljs-keyword">AS</span> `<span class="hljs-type">time</span>`,<br>    REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">AS</span> `key_word`,<br><br>    <span class="hljs-built_in">JSON_VALUE</span>(REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">3</span>), <span class="hljs-string">&#x27;$.key1&#x27;</span> RETURNING <span class="hljs-type">INT</span>) <span class="hljs-keyword">AS</span> `key1`,<br>    <span class="hljs-built_in">JSON_VALUE</span>(REGEXP_EXTRACT(`log`, <span class="hljs-string">&#x27;(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125; \d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;) (.*?) (.*)&#x27;</span>, <span class="hljs-number">3</span>), <span class="hljs-string">&#x27;$.key2&#x27;</span>) <span class="hljs-keyword">AS</span> `key2`<br><span class="hljs-keyword">FROM</span><br>    `ods_log`;<br></code></pre></td></tr></table></figure><blockquote><p>作为一个有洁癖的程序员，一个正则表达式和json函数重复使用显然是不可接受的，需要思考一下如何简化我们的SQL？</p></blockquote><h1 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h1><p>有了结构化的数据，我们就可以基于此计算指标并做一些分析。这里我们利用Flink SQL的Windowing TVFs为例：<img src="https://nightlies.apache.org/flink/flink-docs-master/fig/tumbling-windows.svg" alt="Tumble Window"></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> dws_metric (<br>    `window_start` STRING,<br>    `window_end` STRING,<br>    `dim` STRING,<br>    `metric` <span class="hljs-type">BIGINT</span>,<br>    <span class="hljs-keyword">PRIMARY</span> KEY (`window_start`, `window_end`, `dim`) <span class="hljs-keyword">NOT</span> ENFORCED<br>);<br><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> dws_metric<br><span class="hljs-keyword">SELECT</span><br>    DATE_FORMAT(`window_start`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    DATE_FORMAT(`window_end`, <span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>) <span class="hljs-keyword">AS</span> `window_end`,<br>    `key_word` <span class="hljs-keyword">AS</span> `dim`,<br>    <span class="hljs-built_in">COUNT</span>(<span class="hljs-keyword">DISTINCT</span> `key2`) <span class="hljs-keyword">AS</span> `metric`<br><span class="hljs-keyword">FROM</span><br>    <span class="hljs-comment">-- Windowing TVFs</span><br>    <span class="hljs-keyword">TABLE</span>(TUMBLE(<span class="hljs-keyword">TABLE</span> `dwd_log`, DESCRIPTOR(`rowtime`), <span class="hljs-type">INTERVAL</span> <span class="hljs-string">&#x27;1&#x27;</span> MINUTES))<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> `key_word`, `window_start`, `window_end`;<br></code></pre></td></tr></table></figure><blockquote><p>实际生产过程中，可能遇到性能问题，Flink也提供了相应<a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/tuning/">性能调优</a>的方法，比如<code>MiniBatch</code>, <code>Local-Global</code>, <code>Split Distinct</code>等。</p></blockquote><h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>之前我们都是默认使用的实时数据流，但有时实时流可能出现问题，这时一般采用离线修正的方法。因为Paimon + Flink组成了流批一体的存储计算，避免了传统Lambda架构在不同存储和计算引擎之间代码切换的麻烦，这里只需要添加一行代码切换成批执行即可：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;execution.runtime-mode&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;batch&#x27;</span>;<br><br>...<br></code></pre></td></tr></table></figure><p>这样我们才是真正的实现了流批一体：使用同一套API、同一套开发范式来实现大数据的流计算和批计算，进而保证处理过程与结果的一致性。</p><blockquote><p>注意：批计算时会将所有窗口触发，而流计算时只会触发watermark到达的窗口。</p></blockquote><h1 id="Event-Driven"><a href="#Event-Driven" class="headerlink" title="Event Driven"></a>Event Driven</h1><p>实时场景中的另外一类重要的应用就是事件驱动型应用，典型的就是监控风控场景。这里我们以监控每天的累积指标为例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 设置状态过期时间</span><br><span class="hljs-keyword">SET</span> <span class="hljs-string">&#x27;table.exec.state.ttl&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;2 d&#x27;</span>;<br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> `dws_alert` (<br>    `window_start` STRING,<br>    `key` STRING,<br>    `<span class="hljs-type">time</span>` STRING,<br>    `metric` <span class="hljs-type">BIGINT</span>,<br>    <span class="hljs-keyword">PRIMARY</span> KEY (`window_start`, `key`) <span class="hljs-keyword">NOT</span> ENFORCED<br>);<br><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> `dws_alert`<br><span class="hljs-keyword">SELECT</span><br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyyMMdd&#x27;</span>) <span class="hljs-keyword">AS</span> `window_start`,<br>    `key_word` <span class="hljs-keyword">AS</span> `key`,<br>    <span class="hljs-built_in">MAX</span>(`<span class="hljs-type">time</span>`) <span class="hljs-keyword">AS</span> `<span class="hljs-type">time</span>`,<br>    <span class="hljs-built_in">SUM</span>(`key1`) <span class="hljs-keyword">AS</span> `metric`<br><span class="hljs-keyword">FROM</span><br>    `dwd_log`<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>    DATE_FORMAT(`<span class="hljs-type">time</span>`, <span class="hljs-string">&#x27;yyyyMMdd&#x27;</span>), `key_word`<br><span class="hljs-keyword">HAVING</span> <span class="hljs-built_in">SUM</span>(`key1`) <span class="hljs-operator">&gt;</span> <span class="hljs-number">10</span>;<br></code></pre></td></tr></table></figure><blockquote><p>虽然利用SQL开发逻辑简单，但监控规则和阈值等不可以变动，如果采用不同任务执行不同规则，那就会极大的浪费计算资源，这时就需要思考如何支持动态规则？</p></blockquote><h2 id="CEP"><a href="#CEP" class="headerlink" title="CEP"></a>CEP</h2><p>Flink SQL也提供了复杂事件处理的能力，我们可以利用 MATCH_RECOGNIZE 子句实现更复杂的应用。这里以求单一日志字段取值不断下降的时期为例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span><br><span class="hljs-keyword">FROM</span> dwd_log<br>    <span class="hljs-keyword">MATCH_RECOGNIZE</span> (<br>        <span class="hljs-keyword">PARTITION</span> <span class="hljs-keyword">BY</span> key_word<br>        <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> rowtime<br>        MEASURES<br>            START_ROW.rowtime <span class="hljs-keyword">AS</span> start_ts,<br>            <span class="hljs-keyword">LAST</span>(VAL_DOWN.rowtime) <span class="hljs-keyword">AS</span> bottom_ts,<br>            <span class="hljs-keyword">LAST</span>(VAL_UP.rowtime) <span class="hljs-keyword">AS</span> end_ts<br>        <span class="hljs-keyword">ONE</span> <span class="hljs-type">ROW</span> <span class="hljs-keyword">PER</span> <span class="hljs-keyword">MATCH</span><br>        AFTER <span class="hljs-keyword">MATCH</span> <span class="hljs-keyword">SKIP</span> <span class="hljs-keyword">TO</span> <span class="hljs-keyword">LAST</span> VAL_UP<br>        <span class="hljs-keyword">PATTERN</span> (START_ROW VAL_DOWN<span class="hljs-operator">+</span> VAL_UP)<br>        <span class="hljs-keyword">DEFINE</span><br>            VAL_DOWN <span class="hljs-keyword">AS</span><br>                (<span class="hljs-keyword">LAST</span>(VAL_DOWN.key1, <span class="hljs-number">1</span>) <span class="hljs-keyword">IS</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">AND</span> VAL_DOWN.key1 <span class="hljs-operator">&lt;</span> START_ROW.key1) <span class="hljs-keyword">OR</span><br>                    VAL_DOWN.key1 <span class="hljs-operator">&lt;</span> <span class="hljs-keyword">LAST</span>(VAL_DOWN.key1, <span class="hljs-number">1</span>),<br>            VAL_UP <span class="hljs-keyword">AS</span><br>                VAL_UP.key1 <span class="hljs-operator">&gt;</span> <span class="hljs-keyword">LAST</span>(VAL_DOWN.key1, <span class="hljs-number">1</span>)<br>    ) MR;<br></code></pre></td></tr></table></figure><p>虽然需要重新学习<a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sql/queries/match_recognize/">模式匹配相关语法</a>，这会导致SQL越来越复杂，但这也说明随着SQL标准的不断发展，SQL的表达能力也在不断地完善。</p><h1 id="Funny-Fact"><a href="#Funny-Fact" class="headerlink" title="Funny Fact"></a>Funny Fact</h1><blockquote><p><a href="https://stackoverflow.com/questions/900055/is-sql-or-even-tsql-turing-complete">SQL是图灵完备的</a></p></blockquote><p>虽然 SQL Is All Your Need 只是一个口号，也不会有人只用SQL去完成一些复杂灵活的任务，但如果只是单纯地从理论上来讲，这也是正确的～</p><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>本篇文章接受了如何用统一的技术栈实现大数据开发, 虽然只是一些简单的示例，但随着大数据的发展，技术正在逐渐走向融合，相信SQL Is All Your Need的未来～</p><blockquote><p>本文所有代码可参考：<a href="https://github.com/syntomic/qflink/tree/main/qflink-sql/qflink-sql-sdk/src/test/resources/sqls/sql_is_all_your_need/flink_sql">SQL IS ALL Your Need: Flink SQL</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink SQL</tag>
      
      <tag>Flink</tag>
      
      <tag>Paimon</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人开发环境配置</title>
    <link href="/2023/03/05/%E4%B8%AA%E4%BA%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2023/03/05/%E4%B8%AA%E4%BA%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>编程首先就是需要一个开发环境，本篇文章记录了个人认为Linux平台下搭建一个良好开发环境的相应配置。</p><span id="more"></span><h1 id="Oh-My-ZSH"><a href="#Oh-My-ZSH" class="headerlink" title="Oh My ZSH"></a>Oh My ZSH</h1><ul><li><p>安装zsh</p><ul><li>有root权限时：<code>apt install zsh</code></li><li>无root权限时<ul><li>需要源码编译安装  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">wget -O zsh.tar.xz https://sourceforge.net/projects/zsh/files/latest/download<br><span class="hljs-built_in">mkdir</span> zsh &amp;&amp; unxz zsh.tar.xz &amp;&amp; tar -xvf zsh.tar -C zsh --strip-components 1<br><span class="hljs-built_in">cd</span> zsh<br><br>./configure --prefix=<span class="hljs-variable">$HOME</span><br>make<br>make install<br></code></pre></td></tr></table></figure></li><li>troubleshooting<ul><li><code>configure: error: &quot;No terminal handling library was found on your system. This is probably a library called curses or ncurses. You may need to install a package called &#39;curses-devel&#39; or &#39;ncurses-devel&#39; on your system&quot;</code><ul><li>同样下载源码安装<code>ncurses</code>  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">wget https://ftp.gnu.org/pub/gnu/ncurses/ncurses-6.1.tar.gz<br>tar xvfz ncurses-6.1.tar.gz<br><span class="hljs-built_in">cd</span> ncurses-6.1<br>./configure --prefix=<span class="hljs-variable">$HOME</span> --with-shared<br>make<br>make install<br><span class="hljs-comment"># 安装zsh时需要找到相应动态库</span><br><span class="hljs-built_in">export</span> CPPFLAGS=<span class="hljs-string">&quot;-I<span class="hljs-variable">$HOME</span>/include&quot;</span> LDFLAGS=<span class="hljs-string">&quot;-L<span class="hljs-variable">$HOME</span>/lib&quot;</span><br></code></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li></ul></li><li><p>安装oh my zsh</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sh -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>&quot;</span><br></code></pre></td></tr></table></figure></li><li><p>安装插件: 在~&#x2F;.zshrc文件中更新配置</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">plugins=(<br>    git<br>    extract<br>    z<br>    zsh-autosuggestions<br>    zsh-syntax-highlighting<br>)<br></code></pre></td></tr></table></figure><ul><li>解压: <code>x file</code></li><li>目录跳转：<code>z dir</code></li><li>自动补全  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/zsh-users/zsh-autosuggestions <span class="hljs-variable">$&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;</span>/plugins/zsh-autosuggestions<br></code></pre></td></tr></table></figure></li><li>高亮命令  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">`git <span class="hljs-built_in">clone</span> https://github.com/zsh-users/zsh-syntax-highlighting.git <span class="hljs-variable">$&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;</span>/plugins/zsh-syntax-highlighting`<br></code></pre></td></tr></table></figure></li></ul></li></ul><h1 id="Software"><a href="#Software" class="headerlink" title="Software"></a>Software</h1><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><ul><li><p>Miniconda3</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh<br>sh Miniconda3-latest-Linux-x86_64.sh<br></code></pre></td></tr></table></figure></li><li><p>设置pip镜像源：~&#x2F;.pip&#x2F;pip.conf</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">global</span>]<br><span class="hljs-keyword">index</span>-url = https://pypi.tuna.tsinghua.edu.cn/simple<br>[install]<br><span class="hljs-keyword">trusted</span>-host = https://pypi.tuna.tsinghua.edu.cn<br></code></pre></td></tr></table></figure></li><li><p>虚拟环境管理</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">conda create --name tmp python=3.7 -y<br>conda remove -n tmp --all<br></code></pre></td></tr></table></figure></li></ul><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><ul><li>JDK<ul><li>下载二进制压缩文件并解压</li><li>设置环境变量JAVA_HOME</li></ul></li><li>MAVEN<ul><li>安装<ul><li>下载二进制压缩文件并解压</li><li>设置环境MAVEN_HOME</li></ul></li><li>配置镜像: ~&#x2F;.m2&#x2F;settings.xml  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">mirror</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>aliyunmaven<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">mirrorOf</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">mirrorOf</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>阿里云公共仓库<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>https://maven.aliyun.com/repository/public<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">mirror</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>spring<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>https://maven.aliyun.com/repository/spring<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">releases</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">enabled</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">enabled</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">releases</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">snapshots</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">enabled</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">enabled</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">snapshots</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span><br></code></pre></td></tr></table></figure></li></ul></li></ul><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><h2 id="K8S"><a href="#K8S" class="headerlink" title="K8S"></a>K8S</h2><h1 id="VSCode"><a href="#VSCode" class="headerlink" title="VSCode"></a>VSCode</h1><h2 id="远程开发"><a href="#远程开发" class="headerlink" title="远程开发"></a>远程开发</h2><ul><li><p>配置本地ssh</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">ssh-keygen -t rsa -P <span class="hljs-string">&#x27;&#x27;</span> -f ~/.ssh/id_rsa<br><span class="hljs-built_in">cat</span> ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys<br><span class="hljs-built_in">chmod</span> 0600 ~/.ssh/authorized_keys<br></code></pre></td></tr></table></figure></li><li><p>将本地公钥复制到远程主机的authorized_keys中</p></li><li><p>配置默认shell</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;terminal.integrated.profiles.linux&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;zsh&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;ZSH_PATH&#125;&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;terminal.integrated.defaultProfile.linux&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;zsh&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;terminal.integrated.shell.linux&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;ZSH_PATH&#125;&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;terminal.integrated.automationProfile.linux&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;ZSH_PATH&#125;&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li></ul><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><ul><li>语言支持<ul><li>Python<ul><li>Python：v2022.2.1924087327版本支持python2.7</li><li>autoDocstring</li></ul></li><li>Java<ul><li>Extension Pack for Java  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;java.jdt.ls.java.home&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&#123;JAVA_LS_PATH&#125;&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;java.configuration.runtimes&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;JavaSE-1.8&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;JAVA_8_PATH&#125;&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;JavaSE-11&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;JAVA_11_PATH&#125;&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;JavaSE-17&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;path&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;JAVA_17_PATH&#125;&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li></ul></li></ul></li><li>特性<ul><li>Better Comments</li><li>Code Spell Checker</li><li>Git Graph</li><li>SonarLint</li></ul></li></ul><h2 id="运行配置"><a href="#运行配置" class="headerlink" title="运行配置"></a>运行配置</h2><ul><li>launch.json<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-comment">// Use IntelliSense to learn about possible attributes.</span><br>    <span class="hljs-comment">// Hover to view descriptions of existing attributes.</span><br>    <span class="hljs-comment">// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span><br>    <span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;0.2.0&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;configurations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Python: Current File&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;python&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;request&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;launch&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;program&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;file&#125;&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;console&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integratedTerminal&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;justMyCode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;args&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java调用Python</title>
    <link href="/2023/02/25/Java%E8%B0%83%E7%94%A8Python/"/>
    <url>/2023/02/25/Java%E8%B0%83%E7%94%A8Python/</url>
    
    <content type="html"><![CDATA[<p>每个编程语言都有其适用的范围，当人们需要在结合不同生态去完成一些功能时，就会遇到不同语言通信的问题，本篇文章我们结合一个具体示例，展示如何通过FFI语言交互接口实现在Java中调用Python。</p><span id="more"></span><h1 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h1><ul><li>主要有下面两种原因：<ul><li>使用方式：例如采用Java开发的平台希望给用户提供易用的Python接口</li><li>生态集成：例如将Java中的分布式能力和Python的AI生态相结合</li></ul></li></ul><h1 id="How"><a href="#How" class="headerlink" title="How"></a>How</h1><ul><li><p>现如今有如下的解决方案：</p><ul><li>IPC方案: 比如<a href="https://www.py4j.org/">Py4J</a><ul><li>问题：因为涉及到进程间通信以及序列化，所以会有性能问题</li></ul></li><li>Python运行在JVM的方案：比如<a href="https://www.jython.org/">Jython</a><ul><li>问题：因为CPython现在是主流，所以会有兼容性问题</li></ul></li><li>FFI(Foreign Function Interface): 比如<a href="https://github.com/alibaba/pemja">Pemja</a></li></ul>  <img src="/2023/02/25/Java%E8%B0%83%E7%94%A8Python/FFI.png" class="" title="FFI方案"></li><li><p>本篇文章我们将给出一个示例说明如何使用FFI。</p></li></ul><h1 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h1><ul><li><p>首先需要安装以下环境，如遇到安装问题可以和ChatGPT聊一下~</p><ul><li>编程语言<ul><li>Java: 1.8</li><li>Python: 3.9</li><li>C：c99</li></ul></li><li>编译与链接<ul><li>gcc：动态链接</li></ul></li></ul></li></ul><blockquote><p>由于笔者开发环境采用MacOS + x86平台，所以以下教程只对此平台有效，后续再补上其他环境的相应命令</p></blockquote><h1 id="Learn-By-Doing"><a href="#Learn-By-Doing" class="headerlink" title="Learn By Doing"></a>Learn By Doing</h1><p><em><strong>目标：Java传入日期参数, 由Python返回星期几</strong></em></p><ol><li><p>编写主体Java代码</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> cn.syntomic.ffi;<br><br><span class="hljs-comment">/** Foreign function interface demo */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">FFIDemo</span> &#123;<br><br>    <span class="hljs-keyword">static</span> &#123;<br>        System.load(System.getenv(<span class="hljs-string">&quot;LIBPYTHON&quot;</span>));<br>        System.load(String.format(<span class="hljs-string">&quot;%s/FFIDemo.dylib&quot;</span>, System.getProperty(<span class="hljs-string">&quot;user.dir&quot;</span>)));<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        System.out.println(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FFIDemo</span>().dayOfWeek(<span class="hljs-string">&quot;1994-05-05&quot;</span>));<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 本地方法判断日期是星期几</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> date 日期</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">native</span> <span class="hljs-type">int</span> <span class="hljs-title function_">dayOfWeek</span><span class="hljs-params">(String date)</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>可以看出我们需要首先导入两个共享库<ul><li>运行Python所需的libpython库: 可以利用<a href="https://pypi.org/project/find-libpython/">find-libpython</a>得出</li><li>本地方法实现后的动态FFIDemo库：之后会介绍如何编译生成</li></ul></li></ul></li><li><p>生成Header文件</p> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">javac -h src/main/c/cn/syntomic/ffi/include src/main/java/cn/syntomic/ffi/FFIDemo.java<br></code></pre></td></tr></table></figure><ul><li>可见我们需要实现一个C方法  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">JNIEXPORT jint JNICALL <span class="hljs-title function_">Java_cn_syntomic_ffi_FFIDemo_dayOfWeek</span><br><span class="hljs-params">(JNIEnv *, jobject, jstring)</span>;<br></code></pre></td></tr></table></figure><ul><li>方法名: 由Java包名+类名+方法名组成</li><li>方法参数<ul><li><code>JNIEnv</code>: 通过这个指针可以从运行的JVM中访问所需的类、对象、字段和方法</li><li><code>jobject</code>: 方法所属于的Java对象</li><li><code>jstring</code>: C JNI类型，详细对应可见<a href="https://docs.oracle.com/en/java/javase/11/docs/specs/jni/types.html">JNI Types</a></li></ul></li></ul></li></ul></li><li><p>Python模块实现: 直接调用Python函数实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">day_of_week</span>(<span class="hljs-params">date</span>):<br>    <span class="hljs-keyword">return</span> datetime.strptime(date, <span class="hljs-string">&quot;%Y-%d-%m&quot;</span>).weekday() + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li></ol><hr><p>如果要直接去计算星期几，可以利用数论中Zeller公式</p><blockquote><p>w&#x3D;y+[y&#x2F;4]+[c&#x2F;4]-2c+[26(m+1)&#x2F;10]+d-1</p></blockquote><p>所以<code>1994-05-05</code>这个日期的就是星期4&#x3D;(94+[94&#x2F;4]+[19&#x2F;4]-2*19+[26 *(5+1)&#x2F;10 ]+5-1) % 7</p><hr><ol start="4"><li><p>将Python嵌入到C中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c">JNIEXPORT jint JNICALL <span class="hljs-title function_">Java_cn_syntomic_ffi_FFIDemo_dayOfWeek</span><br>  <span class="hljs-params">(JNIEnv* env, jobject thisObject, jstring date)</span> &#123;<br>    <span class="hljs-type">int</span> weekOfDay;<br><br>    <span class="hljs-comment">// 初始化python解释器</span><br>    Py_Initialize();<br><br>    <span class="hljs-comment">// 导入实现Python函数</span><br>    <span class="hljs-type">const</span> <span class="hljs-type">char</span>* pName = <span class="hljs-string">&quot;day_of_week&quot;</span>;<br>    PyRun_SimpleString(<span class="hljs-string">&quot;import sys&quot;</span>);<br>    PyRun_SimpleString(<span class="hljs-string">&quot;sys.path.append(&#x27;./src/main/python/cn/syntomic/ffi&#x27;)&quot;</span>);<br>    PyObject* pModule = PyImport_Import(PyUnicode_FromString(pName));<br>    PyObject* pFunc = PyObject_GetAttrString(pModule, pName);<br><br>    <span class="hljs-comment">// java类型转化为python参数</span><br>    PyObject* pArgs = PyTuple_New(<span class="hljs-number">1</span>);<br>    PyTuple_SetItem(pArgs, <span class="hljs-number">0</span>, PyUnicode_FromString((*env)-&gt;GetStringUTFChars(env, date, <span class="hljs-literal">NULL</span>)));<br><br>    <span class="hljs-comment">// 调用python函数</span><br>    PyObject* pValue = PyObject_CallObject(pFunc, pArgs);<br>    weekOfDay = PyLong_AsLong(pValue);<br><br>    <span class="hljs-comment">// 关闭python解释器</span><br>    <span class="hljs-keyword">if</span> (Py_FinalizeEx() &lt; <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-built_in">exit</span>(<span class="hljs-number">120</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> weekOfDay;<br>  &#125;<br></code></pre></td></tr></table></figure></li><li><p>编译与运行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">export</span> JAVA_HOME=<span class="hljs-variable">$&#123;JAVA_HOME&#125;</span><br><span class="hljs-built_in">export</span> PYTHONHOME=<span class="hljs-variable">$&#123;PYTHONHOME&#125;</span><br><span class="hljs-built_in">export</span> LIBPYTHON=<span class="hljs-variable">$&#123;LIBPYTHON&#125;</span><br><br><span class="hljs-comment"># 编译</span><br>gcc -c -fPIC -I<span class="hljs-variable">$&#123;JAVA_HOME&#125;</span>/include -I<span class="hljs-variable">$&#123;JAVA_HOME&#125;</span>/include/darwin -I<span class="hljs-variable">$&#123;PYTHONHOME&#125;</span>/include/python3.9 -I<span class="hljs-variable">$&#123;PYTHONHOME&#125;</span>/include src/main/c/cn/syntomic/ffi/cn_syntomic_ffi_FFIDemo.c -o FFIDemo.o<br><span class="hljs-comment"># 生成动态链接库</span><br>gcc -dynamiclib -L<span class="hljs-variable">$&#123;PYTHONHOME&#125;</span>/lib -lpython3.9 -ldl -o FFIDemo.dylib FFIDemo.o<br><br>javac -d target/classes/cn/syntomic/ffi src/main/java/cn/syntomic/ffi/FFIDemo.java<br>java -<span class="hljs-built_in">cp</span> target/classes cn.syntomic.ffi.FFIDemo<br></code></pre></td></tr></table></figure></li></ol><ul><li>最终就会输出<blockquote><p>4</p></blockquote></li></ul><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>本篇文章我们以一个示例展示如何使用FFI，详细代码参考<a href="https://github.com/syntomic/ffi_demo">ffi_demo</a>, 深入研究的话可以参考<a href="https://github.com/alibaba/pemja">Pemja</a></p><h1 id="Refer"><a href="#Refer" class="headerlink" title="Refer"></a>Refer</h1><ol><li><a href="https://www.baeldung.com/jni">Guide to JNI</a></li><li><a href="https://docs.python.org/3/extending/embedding.html">Embedding Python in Another Application</a></li><li><a href="https://developer.aliyun.com/article/902591">基于 FFI 的 PyFlink 下一代 Python 运行时介绍</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>FFI</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
